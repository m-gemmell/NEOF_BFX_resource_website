{
  "hash": "a667114effd323e979763d3b17080889",
  "result": {
    "markdown": "---\ntitle: \"Logistic regression\"\nsubtitle: \"<br><br> Data Science in a Box\"\nauthor: \"[datasciencebox.org](https://datasciencebox.org/)\"\noutput:\n  xaringan::moon_reader:\n    css: [\"../xaringan-themer.css\", \"../slides.css\"]\n    lib_dir: libs\n    anchor_sections: FALSE\n    nature:\n      ratio: \"16:9\"\n      highlightLines: true\n      highlightStyle: solarized-light\n      countIncrementalSlides: false\n---\n\n\n\n\nlayout: true\n  \n<div class=\"my-footer\">\n<span>\n<a href=\"https://datasciencebox.org\" target=\"_blank\">datasciencebox.org</a>\n</span>\n</div> \n\n---\n\n::: {.cell layout-align=\"center\"}\n\n:::\n\n\nclass: middle\n\n# Predicting categorical data\n\n\n---\n\n## Spam filters\n\n.pull-left-narrow[\n- Data from 3921 emails and 21 variables on them\n- Outcome: whether the email is spam or not\n- Predictors: number of characters, whether the email had \"Re:\" in the subject, time at which email was sent, number of times the word \"inherit\" shows up in the email, etc.\n]\n.pull-right-wide[\n.small[\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nlibrary(openintro)\nglimpse(email)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nRows: 3,921\nColumns: 21\n$ spam         <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ to_multiple  <fct> 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, …\n$ from         <fct> 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, …\n$ cc           <int> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, …\n$ sent_email   <fct> 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, …\n$ time         <dttm> 2012-01-01 01:16:41, 2012-01-01 02:03:59,…\n$ image        <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, …\n$ attach       <dbl> 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, …\n$ dollar       <dbl> 0, 0, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ winner       <fct> no, no, no, no, no, no, no, no, no, no, no…\n$ inherit      <dbl> 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ viagra       <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ password     <dbl> 0, 0, 0, 0, 2, 2, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ num_char     <dbl> 11.370, 10.504, 7.773, 13.256, 1.231, 1.09…\n$ line_breaks  <int> 202, 202, 192, 255, 29, 25, 193, 237, 69, …\n$ format       <fct> 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, …\n$ re_subj      <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, …\n$ exclaim_subj <dbl> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ urgent_subj  <fct> 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, …\n$ exclaim_mess <dbl> 0, 1, 6, 48, 1, 1, 1, 18, 1, 0, 2, 1, 0, 1…\n$ number       <fct> big, small, small, small, none, none, big,…\n```\n:::\n:::\n]\n]\n\n---\n\n\n.question[\nWould you expect longer or shorter emails to be spam?\n]\n\n--\n\n.pull-left[\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](u4-d06-logistic-reg_files/figure-html/unnamed-chunk-3-1.png){fig-align='center' width=100%}\n:::\n:::\n\n]\n.pull-right[\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 2\n  spam  mean_num_char\n  <fct>         <dbl>\n1 0             11.3 \n2 1              5.44\n```\n:::\n:::\n\n]\n\n\n---\n\n.question[\nWould you expect emails that have subjects starting with \"Re:\", \"RE:\", \"re:\", or \"rE:\" to be spam or not?\n]\n\n--\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](u4-d06-logistic-reg_files/figure-html/unnamed-chunk-5-1.png){fig-align='center' width=60%}\n:::\n:::\n\n---\n\n\n## Modelling spam\n\n- Both number of characters and whether the message has \"re:\" in the subject might be related to whether the email is spam. How do we come up with a model that will let us explore this relationship?\n\n--\n- For simplicity, we'll focus on the number of characters (`num_char`) as predictor, but the model we describe can be expanded to take multiple predictors as well.\n\n\n---\n\n## Modelling spam\n\nThis isn't something we can reasonably fit a linear model to -- we need something different!\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](u4-d06-logistic-reg_files/figure-html/unnamed-chunk-6-1.png){fig-align='center' width=70%}\n:::\n:::\n\n---\n\n\n## Framing the problem\n\n- We can treat each outcome (spam and not) as successes and failures arising from separate Bernoulli trials\n  - Bernoulli trial: a random experiment with exactly two possible outcomes, \"success\" and \"failure\", in which the probability of success is the same every time the experiment is conducted\n\n--\n- Each Bernoulli trial can have a separate probability of success\n\n\n$$ y_i ∼ Bern(p) $$\n\n\n--\n- We can then use the predictor variables to model that probability of success, $p_i$\n\n--\n- We can't just use a linear model for $p_i$ (since $p_i$ must be between 0 and 1) but we can transform the linear model to have the appropriate range\n\n\n---\n\n## Generalized linear models\n\n- This is a very general way of addressing many problems in regression and the resulting models are called **generalized linear models (GLMs)**\n\n--\n- Logistic regression is just one example\n\n---\n\n\n## Three characteristics of GLMs\n\nAll GLMs have the following three characteristics:\n\n1. A probability distribution describing a generative model for the outcome variable\n\n--\n2. A linear model:\n\n$$\\eta = \\beta_0 + \\beta_1 X_1 + \\cdots + \\beta_k X_k$$\n\n\n--\n3. A link function that relates the linear model to the parameter of the outcome distribution\n  \n\n---\n\nclass: middle\n\n# Logistic regression\n\n---\n\n\n## Logistic regression\n\n- Logistic regression is a GLM used to model a binary categorical outcome using numerical and categorical predictors\n\n--\n- To finish specifying the Logistic model we just need to define a reasonable link function that connects $\\eta_i$ to $p_i$: logit function\n\n--\n- **Logit function:** For $0\\le p \\le 1$\n\n\n$$logit(p) = \\log\\left(\\frac{p}{1-p}\\right)$$\n\n---\n\n## Logit function, visualised\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](u4-d06-logistic-reg_files/figure-html/unnamed-chunk-7-1.png){fig-align='center' width=60%}\n:::\n:::\n\n---\n\n\n## Properties of the logit\n\n- The logit function takes a value between 0 and 1 and maps it to a value between $-\\infty$ and $\\infty$\n\n--\n- Inverse logit (logistic) function:\n\n$$g^{-1}(x) = \\frac{\\exp(x)}{1+\\exp(x)} = \\frac{1}{1+\\exp(-x)}$$\n\n\n--\n- The inverse logit function takes a value between $-\\infty$ and $\\infty$ and maps it to a value between 0 and 1\n\n--\n- This formulation is also useful for interpreting the model, since the logit can be interpreted as the log odds of a success -- more on this later\n\n\n---\n\n## The logistic regression model\n\n- Based on the three GLM criteria we have\n  - $y_i \\sim \\text{Bern}(p_i)$\n  - $\\eta_i = \\beta_0+\\beta_1 x_{1,i} + \\cdots + \\beta_n x_{n,i}$\n  - $\\text{logit}(p_i) = \\eta_i$\n\n--\n- From which we get\n\n\n$$p_i = \\frac{\\exp(\\beta_0+\\beta_1 x_{1,i} + \\cdots + \\beta_k x_{k,i})}{1+\\exp(\\beta_0+\\beta_1 x_{1,i} + \\cdots + \\beta_k x_{k,i})}$$\n\n---\n\n\n## Modeling spam\n\nIn R we fit a GLM in the same way as a linear model except we\n\n- specify the model with `logistic_reg()`\n- use `\"glm\"` instead of `\"lm\"` as the engine \n- define `family = \"binomial\"` for the link function to be used in the model\n\n--\n\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\nspam_fit <- logistic_reg() %>%\n  set_engine(\"glm\") %>%\n  fit(spam ~ num_char, data = email, family = \"binomial\")\n\ntidy(spam_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic   p.value\n  <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)  -1.80     0.0716     -25.1  2.04e-139\n2 num_char     -0.0621   0.00801     -7.75 9.50e- 15\n```\n:::\n:::\n\n---\n\n## Spam model\n\n::: {.cell layout-align=\"center\"}\n\n```{.r .cell-code}\ntidy(spam_fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 2 × 5\n  term        estimate std.error statistic   p.value\n  <chr>          <dbl>     <dbl>     <dbl>     <dbl>\n1 (Intercept)  -1.80     0.0716     -25.1  2.04e-139\n2 num_char     -0.0621   0.00801     -7.75 9.50e- 15\n```\n:::\n:::\n\n--\n\nModel:\n\n$$\\log\\left(\\frac{p}{1-p}\\right) = -1.80-0.0621\\times \\text{num_char}$$\n\n\n---\n\n\n## P(spam) for an email with 2000 characters \n\n\n$$\\log\\left(\\frac{p}{1-p}\\right) = -1.80-0.0621\\times 2$$\n\n--\n\n$$\\frac{p}{1-p} = \\exp(-1.9242) = 0.15 \\rightarrow p = 0.15 \\times (1 - p)$$\n\n--\n\n$$p = 0.15 - 0.15p \\rightarrow 1.15p = 0.15$$\n\n--\n\n$$p = 0.15 / 1.15 = 0.13$$\n\n---\n\n.question[\nWhat is the probability that an email with 15000 characters is spam? What about an email with 40000 characters?\n]\n\n--\n\n.pull-left[\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](u4-d06-logistic-reg_files/figure-html/spam-predict-viz-1.png){fig-align='center' width=100%}\n:::\n:::\n]\n.pull-right[\n- .light-blue[2K chars: P(spam) = 0.13]\n- .yellow[15K chars, P(spam) = 0.06]\n- .green[40K chars, P(spam) = 0.01]\n]\n\n---\n\n\n.question[\nWould you prefer an email with 2000 characters to be labelled as spam or not? How about 40,000 characters?\n]\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![](u4-d06-logistic-reg_files/figure-html/unnamed-chunk-10-1.png){fig-align='center' width=60%}\n:::\n:::\n\n---\n\nclass: middle\n\n# Sensitivity and specificity\n\n---\n\n\n## False positive and negative\n\n|                         | Email is spam                 | Email is not spam             |\n|-------------------------|-------------------------------|-------------------------------|\n| Email labelled spam     | True positive                 | False positive (Type 1 error) |\n| Email labelled not spam | False negative (Type 2 error) | True negative                 |\n\n--\n- False negative rate = P(Labelled not spam | Email spam) = FN / (TP + FN) \n\n- False positive rate = P(Labelled spam | Email not spam) = FP / (FP + TN)\n\n\n---\n\n## Sensitivity and specificity\n\n|                         | Email is spam                 | Email is not spam             |\n|-------------------------|-------------------------------|-------------------------------|\n| Email labelled spam     | True positive                 | False positive (Type 1 error) |\n| Email labelled not spam | False negative (Type 2 error) | True negative                 |\n\n--\n\n- Sensitivity = P(Labelled spam | Email spam) = TP / (TP + FN)\n  - Sensitivity = 1 − False negative rate\n  \n- Specificity = P(Labelled not spam | Email not spam) = TN / (FP + TN) \n  - Specificity = 1 − False positive rate\n\n---\n\n\n.question[\nIf you were designing a spam filter, would you want sensitivity and specificity to be high or low? What are the trade-offs associated with each decision? \n]\n",
    "supporting": [
      "u4-d06-logistic-reg_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {
      "include-in-header": [
        "<link href=\"../../../site_libs/font-awesome/css/all.css\" rel=\"stylesheet\" />\n<link href=\"../../../site_libs/font-awesome/css/v4-shims.css\" rel=\"stylesheet\" />\n<link href=\"../../../site_libs/panelset/panelset.css\" rel=\"stylesheet\" />\n<script src=\"../../../site_libs/panelset/panelset.js\"></script>\n"
      ]
    },
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}